# -*- coding: utf-8 -*-
"""BCI_ML_Within_Subject_EEG-ITNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MKgNrBKTWogHi3PD-cUlhym-Q_rQZfYA
"""

pip install mne

pip install tensorflow_addons

"""# Data Loading (SEED-IV): Load the extracted and transformed data

"""

import scipy.io
import pandas as pd
import numpy as np
import os
import glob
import matplotlib.pyplot as plt
import warnings
import scipy.signal as signal
import tensorflow as tf
from sklearn.preprocessing import StandardScaler

# Ignore warnings
warnings.filterwarnings('ignore')

# Mount Google Drive
from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = os.path.join('CE807/BCITL/Data/eeg_raw_data')
GOOGLE_DRIVE_PATH = os.path.join('gdrive', 'MyDrive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)
print('List session files: ', os.listdir(GOOGLE_DRIVE_PATH))

import sys
sys.path.append('/content/gdrive/My Drive/CE807/BCITL/Code')
import tensorflow as tf
import tl_helper

from sklearn import metrics
from keras.callbacks import EarlyStopping, ModelCheckpoint
from tl_helper import preprocess_eeg, split_eeg
from tl_helper import process_file, divide_data
from tl_helper import get_session_labels ,get_categorical_labels
from tl_helper import get_participant_files
from tl_helper import get_session_number
from tl_helper import  process_eeg_chunks_for_EEGNET
from tl_helper import EEGNet,  EEGNet_FirstLayerOnly
print ("Import tl_helper sucessfully")

import matplotlib.pyplot as plt
import numpy as np

def plot_eeg_channels(eeg_data):
    num_channels = eeg_data.shape[0]  # Number of channels
    num_samples = eeg_data.shape[1]  # Number of samples
    plt.figure(figsize=(15, 3))
    plt.plot(eeg_data.T)
    plt.show()

from sklearn import metrics
from keras.callbacks import EarlyStopping, ModelCheckpoint

def data_preprocessing_splitting(participant_files, num_participants, participant_num, n_chunks):
    session1_label, session2_label, session3_label = get_session_labels()
    print("  *** **** ")
    print("Participant Data:", participant_num)

    for session_num in range(1, 4):  # Loop through session 1, session 2, and session 3
        # Find the appropriate session label based on the current session number

        # Get the files for the current participant
        files = participant_files[participant_num]
        # Sort the files based on the session number and get session number from path
        sorted_files = sorted(files, key=get_session_number)

        file_path = sorted_files[session_num - 1]  # Adjust the index since sessions are 1-indexed

        if session_num == 1:
            print("Session 1 file_path session1_label: ", file_path)
            eeg_chunks_list_train_S1, label_list_S1 = process_file(file_path, session1_label, n_chunks)

        elif session_num == 2:
            print("Session 2 file_path session2_label: ", file_path)
            eeg_chunks_list_tune_S2, label_list_tune_S2, eeg_chunks_list_train_S2, label_list_train_S2 = divide_data(file_path, session2_label, n_chunks)

        elif session_num == 3:
            print("Session 3 file_path session3_label: ", file_path)
            eeg_chunks_list_tune_S3, label_list_tune_S3, eeg_chunks_list_train_S3, label_list_train_S3 = divide_data(file_path, session3_label, n_chunks)

            # For Participant i - Session 1

            print(" *** ** Participant Data Summary ** *** : ",  participant_num)

            print("Participant - Session 1")
            print("No of Trails (Train) ", len(eeg_chunks_list_train_S1))
            print("Shape of each eeg_chunks ", eeg_chunks_list_train_S1[0].shape)
            print("----------------------")

            # For Participant i - Session 2
            print("Participant - Session 2")
            print("No of Trails (Train)", len(eeg_chunks_list_train_S2))
            print("Shape of eeg_chunks", eeg_chunks_list_train_S2[0].shape)
            print("No of Trails (Tune)", len(eeg_chunks_list_tune_S2))
            print("Shape of eeg_chunks",  eeg_chunks_list_tune_S2[0].shape)
            print("----------------------")

            # For Participant i - Session 3
            print("Participant - Session 3")
            print("No of Trails (Train)",len(eeg_chunks_list_train_S3))
            print("Shape of eeg_chunks", eeg_chunks_list_train_S3[0].shape)
            print("No of Trails (Tune)", len(eeg_chunks_list_tune_S3))
            print("Shape of eeg_chunks", eeg_chunks_list_tune_S3[0].shape)
            print("----------------------")

            print("-----------process_eeg_chunks_for_Modeling-----------")

            ChunkData_session1 = process_eeg_chunks_for_EEGNET(eeg_chunks_list_train_S1)
            ChunkData_session2_train = process_eeg_chunks_for_EEGNET(eeg_chunks_list_train_S2)
            ChunkData_session2_tune = process_eeg_chunks_for_EEGNET(eeg_chunks_list_tune_S2)
            ChunkData_session3_train = process_eeg_chunks_for_EEGNET(eeg_chunks_list_train_S3)
            ChunkData_session3_tune = process_eeg_chunks_for_EEGNET(eeg_chunks_list_tune_S3)

            categorical_labels, categorical_labels_2_tune, categorical_labels_2_train, categorical_labels_3_tune, categorical_labels_3_train = get_categorical_labels(label_list_S1, label_list_tune_S2, label_list_train_S2, label_list_tune_S3, label_list_train_S3)
            print("ChunkData_session1_train : ", ChunkData_session1.shape)
            print("ChunkData_session2_train : ", ChunkData_session2_train.shape)
            print("ChunkData_session2_tune : ", ChunkData_session2_tune.shape)
            print("ChunkData_session3_train : ", ChunkData_session3_train.shape)
            print("ChunkData_session3_tune : ", ChunkData_session3_tune.shape)



            print("-----------data_preprocessing_splitting_done-----------")
    # Return the required variables
    return (
        ChunkData_session1,
        ChunkData_session2_train,
        ChunkData_session2_tune,
        ChunkData_session3_train,
        ChunkData_session3_tune,
        categorical_labels,
        categorical_labels_2_tune,
        categorical_labels_2_train,
        categorical_labels_3_tune,
        categorical_labels_3_train
    )

"""@Pipeline"""

participant_files = get_participant_files(GOOGLE_DRIVE_PATH)
print ("participant_files : ", participant_files)
num_participants = 15
participant_num = 15
n_chunks = 700

# Call the function and store the returned values
(
    ChunkData_session1,
    ChunkData_session2_train,
    ChunkData_session2_tune,
    ChunkData_session3_train,
    ChunkData_session3_tune,
    categorical_labels,
    categorical_labels_2_tune,
    categorical_labels_2_train,
    categorical_labels_3_tune,
    categorical_labels_3_train
) = data_preprocessing_splitting(participant_files, num_participants, participant_num, n_chunks)

import numpy as np
from sklearn import metrics
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

def modeling_EEG_ITNet(ChunkData_session1, ChunkData_session2_train, ChunkData_session2_tune,
             ChunkData_session3_train, ChunkData_session3_tune, categorical_labels,
             categorical_labels_2_train, categorical_labels_2_tune, categorical_labels_3_train,
             categorical_labels_3_tune, Chans=62, Samples =700, participant_num=1):

    # Print data shapes
    print("   **********   ")
    print("   ***** Data Arrangement*****   ")
    print("categorical_labels.shape ", categorical_labels.shape)
    print("categorical_labels_2_train:", categorical_labels_2_train.shape)
    print("Categorical_labels_2_tune:", categorical_labels_2_tune.shape)
    print("categorical_labels_3_train:", categorical_labels_3_train.shape)
    print("categorical_labels_3_tune:", categorical_labels_3_tune.shape)
    print("ChunkData_session1_train : ", ChunkData_session1.shape)
    print("ChunkData_session2_train : ", ChunkData_session2_train.shape)
    print("ChunkData_session2_tune : ", ChunkData_session2_tune.shape)
    print("ChunkData_session3_train : ", ChunkData_session3_train.shape)
    print("ChunkData_session3_tune : ", ChunkData_session3_tune.shape)

    # Build the model
    model = EEG_ITNet(Chans, Samples)
    print("model.summary()")
    model.summary()

    # Compile the model
    learning_rate = 0.00001
    optimizer = Adam(learning_rate=learning_rate)
    #model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])


    # Define callbacks
    early_stopping = EarlyStopping(monitor='val_loss', patience=100, mode='min', verbose=1, restore_best_weights=True)
    model_filename = f"trained_model_participant_{participant_num}.h5"
    model_checkpoint = ModelCheckpoint(model_filename, monitor='val_loss', save_best_only=True, mode='min')
    callbacks = [early_stopping, model_checkpoint]

    # Prepare data
    categorical_labels_train = np.append(categorical_labels, categorical_labels_2_train, axis=0)
    categorical_labels_train = np.append(categorical_labels_train, categorical_labels_3_train, axis=0)
    print("categorical_labels_train shape: ", categorical_labels_train.shape)

    categorical_labels_tune = np.append(categorical_labels_2_tune, categorical_labels_3_tune, axis=0)
    print("categorical_labels_tune shape: ", categorical_labels_tune.shape)

    ChunkData_train = np.append(ChunkData_session1, ChunkData_session2_train, axis=0)
    ChunkData_train = np.append(ChunkData_train, ChunkData_session3_train, axis=0)
    print("ChunkData_train shape: ", ChunkData_train.shape)

    ChunkData_tune = np.append(ChunkData_session2_tune, ChunkData_session3_tune, axis=0)
    print("ChunkData_tune shape: ", ChunkData_tune.shape)

    # Train the model
    fitted = model.fit(x=ChunkData_train, y=categorical_labels_train, epochs=300, validation_split=0.1, verbose=1, callbacks=callbacks, batch_size=128)
    plot_training_history(fitted)

    # Evaluate the model
    predicted = model.predict(x=ChunkData_tune)
    tune_labels_multiclass = np.argmax(categorical_labels_tune, axis=1)
    predicted_labels_multiclass = np.argmax(predicted, axis=1)

    # Calculate metrics
    accuracy = metrics.accuracy_score(tune_labels_multiclass, predicted_labels_multiclass)
    print("Accuracy:", accuracy)

    f1_score = metrics.f1_score(tune_labels_multiclass, predicted_labels_multiclass, average='weighted')
    print("F1-score:", f1_score)

    classification_report = metrics.classification_report(tune_labels_multiclass, predicted_labels_multiclass)
    print("Classification Report:\n", classification_report)

Chans = 62
Samples = 700
participant_num = 15
modeling_EEG_ITNet(ChunkData_session1, ChunkData_session2_train, ChunkData_session2_train,
                                                                    ChunkData_session3_train, ChunkData_session3_tune,
                                                                    categorical_labels, categorical_labels_2_train,
                                                                    categorical_labels_2_train, categorical_labels_3_train,
                                                                    categorical_labels_3_tune, Chans, Samples, participant_num)

"""### EEGNET // https://arxiv.org/abs/1611.08024
### EEGITNET  //https://arxiv.org/abs/2204.06947
"""


# -*- coding: utf-8 -*-
"""TL_Helper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13JXxH7r4ybctW7ve3wkDWMElO01l4Q31
"""

import scipy.io as sio
import pandas as pd
import numpy as np
import os
import glob
import matplotlib.pyplot as plt
import scipy.io
import scipy.signal as signal

import warnings
import tensorflow as tf
from sklearn import metrics

from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, classification_report

# Ignore warnings
warnings.filterwarnings('ignore')

def preprocess_eeg_2(raw_eeg, fs):
    # Apply common average reference (CAR) across all channels
    average_reference = np.mean(raw_eeg, axis=0)
    car_eeg = raw_eeg - average_reference

    # Apply filter between 0.15 Hz and 40 Hz to the CAR-corrected EEG data
    b, a = signal.butter(4, [0.15, 40], 'bandpass', fs=fs)
    filtered_eeg = signal.filtfilt(b, a, car_eeg, axis=1)

    return filtered_eeg

def get_participant_files(parent_folder):
    num_participants = 15
    participant_files = {}

    for participant_num in range(1, num_participants + 1):
        participant_prefix = f"{participant_num}_"
        participant_files[participant_num] = []

        for root, _, files in os.walk(parent_folder):
            for file_name in files:
                if file_name.startswith(participant_prefix):
                    participant_files[participant_num].append(os.path.join(root, file_name))

    return participant_files

def split_eeg(eeg_data, chunk_length):
    # Get the number of channels and the length of each channel's data
    num_channels, channel_length = eeg_data.shape

    #print ("eeg channels : ", num_channels)
    #print ("func : split_eeg ")

    # Calculate the number of chunks for each channel
    n_chunks = channel_length // chunk_length

    # Create an empty array to store the chunked data
    chunks = np.empty((chunk_length, num_channels, n_chunks))

    # Split each channel's data into equal-length chunks
    chunks = np.array_split(eeg_data[:, :chunk_length * n_chunks].T, n_chunks)
    '''
    for channel in range(num_channels):
        channel_data = eeg_data[channel]

        # Split the channel's data into chunks of equal length
        channel_chunks = np.array_split(channel_data[:chunk_length * n_chunks], n_chunks)

        # Store the chunks of the current channel in the resulting array
        for i, chunk in enumerate(channel_chunks):
            chunks[:, channel, i] = chunk
    '''
    print(len(chunks), chunks[0].shape)
    return np.asarray(chunks)

def process_file(file_name, labels, n_chunks):
    eeg_substring = 'eeg'
    keys_to_ignore = ['__header__', '__version__', '__globals__']
    labelcount = 0

    mat = scipy.io.loadmat(file_name)
    print(f"Keys for {file_name}: {mat.keys()}")

    eeg_chunks_list = []  # Initialize an empty list to store the chunks
    label_list = []  # Initialize an empty list to store the labels

    count_chunks = 0

    for trail_name, trail_data in mat.items():
        if trail_name not in keys_to_ignore and eeg_substring in trail_name:
            print("Trail name:", trail_name)
            print("EEG dimensions:", trail_data.shape)
            print("Trail Label:", labels[labelcount])

            fs = 200
            #print("Before pre processing : plot_eeg_channels")
            #plot_eeg_channels(trail_data)

            preprocessed_eeg = preprocess_eeg_2(trail_data, fs)
            print("preprocessed_eeg.shape:", preprocessed_eeg.shape)
            #print("After pre processing : plot_eeg_channels")
            #plot_eeg_channels(trail_data)


            # Split preprocessed EEG data into equal-length chunks
            eeg_chunks = split_eeg(preprocessed_eeg, n_chunks)
            print("Number of chunks:", eeg_chunks.shape[0])
            print("eeg_chunks.shape:", eeg_chunks.shape)

            # Append the chunks to the list
            eeg_chunks_list.append(eeg_chunks)

            # Repeat the label for each chunk and append to the label list
            label_list += [labels[labelcount]] * eeg_chunks.shape[0]
            count_chunks += eeg_chunks.shape[0]

            labelcount = labelcount + 1

            print("----------------------")

    #print('Total number of chunks:', count_chunks)
    #print("Size of eeg_chunks_list:", len(eeg_chunks_list))
    #print("Size of label_list:", len(label_list))

    return eeg_chunks_list, label_list

def divide_data(file_name, labels, n_chunks):
    eeg_substring = 'eeg'
    keys_to_ignore = ['__header__', '__version__', '__globals__']
    labelcount = 0

    eeg_chunks_list_train = []  # Initialize an empty list to store the chunks
    label_list_train = []  # Initialize an empty list to store the labels

    eeg_chunks_list_tune = []  # Initialize an empty list to store the chunks
    label_list_tune = []  # Initialize an empty list to store the labels

    count_chunks_train = 0
    count_chunks_tune = 0

    mat = scipy.io.loadmat(file_name)
    print(f"Keys for {file_name}: {mat.keys()}")

    data_train = []
    data_train_labels = []
    data_tune = []
    data_tune_labels = []

    mat_items = list(mat.items())
    half_length = len(mat_items) // 2

    for i, (trail_name, trail_data) in enumerate(mat_items):

        if trail_name not in keys_to_ignore and eeg_substring in trail_name:

            print("Trail name:", trail_name)
            # print("EEG dimensions:", trail_data.shape)
            print("Trail Label:", labels[labelcount])

            if i >= (half_length):
                data_tune = trail_data

                ###########

                fs = 200
                preprocessed_eeg_tune = preprocess_eeg_2(data_tune, fs)
                #print("preprocessed_eeg.shape:", preprocessed_eeg_tune.shape)

                # Split preprocessed EEG data into equal-length chunks
                eeg_chunks_tune = split_eeg(preprocessed_eeg_tune, n_chunks)
                #print("Number of chunks:", eeg_chunks_tune.shape[0])
                #print("eeg_chunks.shape:", eeg_chunks_tune.shape)

                # Append the chunks to the list
                eeg_chunks_list_tune.append(eeg_chunks_tune)

                # Repeat the label for each chunk and append to the label list
                label_list_tune += [labels[labelcount]] * eeg_chunks_tune.shape[0]
                count_chunks_tune += eeg_chunks_tune.shape[0]
                #print("labelcount:", labelcount)


                ###########

                print("Trail name (Tune):", trail_name)
                print("Trail label:", labels[labelcount])
                print("----------------------")

                labelcount += 1



            else:
                data_train = trail_data

                ###########

                fs = 200
                preprocessed_eeg_train = preprocess_eeg_2(data_train, fs)
                #print("preprocessed_eeg.shape:", preprocessed_eeg_train.shape)

                # Split preprocessed EEG data into equal-length chunks
                #n_chunks = 1000
                eeg_chunks_train = split_eeg(preprocessed_eeg_train, n_chunks)
                print("Number of chunks:", eeg_chunks_train.shape[0])
                print("eeg_chunks.shape:", eeg_chunks_train.shape)

                # Append the chunks to the list
                eeg_chunks_list_train.append(eeg_chunks_train)

                # Repeat the label for each chunk and append to the label list
                label_list_train += [labels[labelcount]] * eeg_chunks_train.shape[0]
                count_chunks_train += eeg_chunks_train.shape[0]
                #print("labelcount:", labelcount)


                print("Trail name (Train):", trail_name)
                print("Trail label:", labels[labelcount])
                print("----------------------")
                labelcount += 1

    return eeg_chunks_list_train, label_list_train, eeg_chunks_list_tune, label_list_tune

def process_eeg_chunks_for_EEGNET(eeg_chunks_list):
    newChunkarray = eeg_chunks_list[0]
    newChunkarray_shape = newChunkarray.shape

    for trial in eeg_chunks_list[1:]:
        newChunkarray = np.vstack([newChunkarray, trial])

    newChunkarray = newChunkarray.transpose((0, 2, 1))
    newChunkarray = newChunkarray.reshape(newChunkarray.shape[0], newChunkarray.shape[1], newChunkarray.shape[2], 1)
    #print (" Chunk/Data for EEGNet ", newChunkarray.shape)
    return newChunkarray

def get_session_labels():
    session1_label = np.array([1, 2, 3, 0, 2, 0, 0, 1, 0, 1, 2, 1, 1, 1, 2, 3, 2, 2, 3, 3, 0, 3, 0, 3])
    session2_label = np.array([2, 1, 3, 0, 0, 2, 0, 2, 3, 3, 2, 3, 2, 0, 1, 1, 2, 1, 0, 3, 0, 1, 3, 1])
    session3_label = np.array([1, 2, 2, 1, 3, 3, 3, 1, 1, 2, 1, 0, 2, 3, 3, 0, 2, 3, 0, 0, 2, 0, 1, 0])

    return session1_label, session2_label, session3_label

import tensorflow as tf
def get_categorical_labels(label_list_S1, label_list_train_S2, label_list_tune_S2, label_list_train_S3, label_list_tune_S3):
    categorical_labels_S1 = tf.keras.utils.to_categorical(label_list_S1)
    #print("categorical_labels_S1:", categorical_labels_S1.shape)

    categorical_labels_S2_train = tf.keras.utils.to_categorical(label_list_train_S2)
    #print("categorical_labels_S2_train:", categorical_labels_S2_train.shape)
    categorical_labels_S2_tune = tf.keras.utils.to_categorical(label_list_tune_S2)
    #print("categorical_labels_S2_tune:", categorical_labels_S2_tune.shape)

    categorical_labels_S3_train = tf.keras.utils.to_categorical(label_list_train_S3)
    #print("categorical_labels_S3_train:", categorical_labels_S3_train.shape)
    categorical_labels_S3_tune = tf.keras.utils.to_categorical(label_list_tune_S3)
    #print("categorical_labels_S3_tune:", categorical_labels_S3_tune.shape)

    return categorical_labels_S1, categorical_labels_S2_train, categorical_labels_S2_tune, categorical_labels_S3_train, categorical_labels_S3_tune

# Define a custom sorting key function to extract the session number
def get_session_number(file_path):
    # Split the file path based on '/'
    path_parts = file_path.split('/')
    # Find the session number (second last value in the path)
    session_number = int(path_parts[-2])
    return session_number

"""
 ARL_EEGModels - A collection of Convolutional Neural Network models for EEG
 Signal Processing and Classification, using Keras and Tensorflow

 Requirements:
    (1) tensorflow == 2.X (as of this writing, 2.0 - 2.3 have been verified
        as working)

 To run the EEG/MEG ERP classification sample script, you will also need

    (4) mne >= 0.17.1
    (5) PyRiemann >= 0.2.5
    (6) scikit-learn >= 0.20.1
    (7) matplotlib >= 2.2.3

 To use:

    (1) Place this file in the PYTHONPATH variable in your IDE (i.e.: Spyder)
    (2) Import the model as

        from EEGModels import EEGNet

        model = EEGNet(nb_classes = ..., Chans = ..., Samples = ...)

    (3) Then compile and fit the model

        model.compile(loss = ..., optimizer = ..., metrics = ...)
        fitted    = model.fit(...)
        predicted = model.predict(...)

 Portions of this project are works of the United States Government and are not
 subject to domestic copyright protection under 17 USC Sec. 105.  Those
 portions are released world-wide under the terms of the Creative Commons Zero
 1.0 (CC0) license.

 Other portions of this project are subject to domestic copyright protection
 under 17 USC Sec. 105.  Those portions are licensed under the Apache 2.0
 license.  The complete text of the license governing this material is in
 the file labeled LICENSE.TXT that is a part of this project's official
 distribution.
"""
import tensorflow
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Activation, Permute, Dropout
from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D
from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import SpatialDropout2D
from tensorflow.keras.regularizers import l1_l2
from tensorflow.keras.layers import Input, Flatten
from tensorflow.keras.constraints import max_norm
from tensorflow.keras import backend as K


def EEGNet(nb_classes, Chans = 64, Samples = 128,
             dropoutRate = 0.5, kernLength = 64, F1 = 8,
             D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):
    """ Keras Implementation of EEGNet
    http://iopscience.iop.org/article/10.1088/1741-2552/aace8c/meta

    Note that this implements the newest version of EEGNet and NOT the earlier
    version (version v1 and v2 on arxiv). We strongly recommend using this
    architecture as it performs much better and has nicer properties than
    our earlier version. For example:

        1. Depthwise Convolutions to learn spatial filters within a
        temporal convolution. The use of the depth_multiplier option maps
        exactly to the number of spatial filters learned within a temporal
        filter. This matches the setup of algorithms like FBCSP which learn
        spatial filters within each filter in a filter-bank. This also limits
        the number of free parameters to fit when compared to a fully-connected
        convolution.

        2. Separable Convolutions to learn how to optimally combine spatial
        filters across temporal bands. Separable Convolutions are Depthwise
        Convolutions followed by (1x1) Pointwise Convolutions.


    While the original paper used Dropout, we found that SpatialDropout2D
    sometimes produced slightly better results for classification of ERP
    signals. However, SpatialDropout2D significantly reduced performance
    on the Oscillatory dataset (SMR, BCI-IV Dataset 2A). We recommend using
    the default Dropout in most cases.

    Assumes the input signal is sampled at 128Hz. If you want to use this model
    for any other sampling rate you will need to modify the lengths of temporal
    kernels and average pooling size in blocks 1 and 2 as needed (double the
    kernel lengths for double the sampling rate, etc). Note that we haven't
    tested the model performance with this rule so this may not work well.

    The model with default parameters gives the EEGNet-8,2 model as discussed
    in the paper. This model should do pretty well in general, although it is
	advised to do some model searching to get optimal performance on your
	particular dataset.

    We set F2 = F1 * D (number of input filters = number of output filters) for
    the SeparableConv2D layer. We haven't extensively tested other values of this
    parameter (say, F2 < F1 * D for compressed learning, and F2 > F1 * D for
    overcomplete). We believe the main parameters to focus on are F1 and D.

    Inputs:

      nb_classes      : int, number of classes to classify
      Chans, Samples  : number of channels and time points in the EEG data
      dropoutRate     : dropout fraction
      kernLength      : length of temporal convolution in first layer. We found
                        that setting this to be half the sampling rate worked
                        well in practice. For the SMR dataset in particular
                        since the data was high-passed at 4Hz we used a kernel
                        length of 32.
      F1, F2          : number of temporal filters (F1) and number of pointwise
                        filters (F2) to learn. Default: F1 = 8, F2 = F1 * D.
      D               : number of spatial filters to learn within each temporal
                        convolution. Default: D = 2
      dropoutType     : Either SpatialDropout2D or Dropout, passed as a string.

    """

    if dropoutType == 'SpatialDropout2D':
        dropoutType = SpatialDropout2D
    elif dropoutType == 'Dropout':
        dropoutType = Dropout
    else:
        raise ValueError('dropoutType must be one of SpatialDropout2D '
                         'or Dropout, passed as a string.')

    input1   = Input(shape = (Chans, Samples, 1))

    ##################################################################
    block1       = Conv2D(F1, (1, kernLength), padding = 'same',
                                   input_shape = (Chans, Samples, 1),
                                   use_bias = False)(input1)
    block1       = BatchNormalization()(block1)
    block1       = DepthwiseConv2D((Chans, 1), use_bias = False,
                                   depth_multiplier = D,
                                   depthwise_constraint = max_norm(1.))(block1)
    block1       = BatchNormalization()(block1)
    block1       = Activation('elu')(block1)
    block1       = AveragePooling2D((1, 4))(block1)
    block1       = dropoutType(dropoutRate)(block1)

    block2       = SeparableConv2D(F2, (1, 16),
                                   use_bias = False, padding = 'same')(block1)
    block2       = BatchNormalization()(block2)
    block2       = Activation('elu')(block2)
    block2       = AveragePooling2D((1, 8))(block2)
    block2       = dropoutType(dropoutRate)(block2)

    flatten      = Flatten(name = 'flatten')(block2)

    dense        = Dense(nb_classes, name = 'dense',
                         kernel_constraint = max_norm(norm_rate))(flatten)
    softmax      = Activation('softmax', name = 'softmax')(dense)

    return Model(inputs=input1, outputs=softmax)

from tensorflow.keras.models import Model, Sequential, load_model
from tensorflow.keras import regularizers
from tensorflow.keras.layers import Input, Dense, Activation, Dropout, SpatialDropout1D, SpatialDropout2D, BatchNormalization
from tensorflow.keras.layers import Flatten, InputSpec, Layer, Concatenate, AveragePooling2D, MaxPooling2D, Reshape, Permute
from tensorflow.keras.layers import Conv2D, LSTM , SeparableConv2D, DepthwiseConv2D, ConvLSTM2D, LayerNormalization
from tensorflow.keras.layers import TimeDistributed, Lambda, AveragePooling1D, GRU, Attention, Dot, Add, Conv1D, Multiply
from tensorflow.keras.constraints import max_norm, unit_norm
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.optimizers import Adam
from tensorflow_addons.layers import WeightNormalization
from tensorflow.keras.utils import plot_model

import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, DepthwiseConv2D, Activation, AveragePooling2D, Dropout, Add, Concatenate, Dense, Flatten
from tensorflow.keras.constraints import max_norm
from tensorflow.keras.models import Model

def EEG_ITNet(Chans, Samples):
    analysis_type = 1
    drop_rate = 0.4
    Fs = 200          # Sampling frequency
    n_ff = [2,4,8]    # Number of frequency filters for each inception module of EEG-ITNet
    n_sf = [1,1,1]    # Number of spatial filters in each frequency sub-band of EEG-ITNet

    Input_block = Input(shape=(Chans, Samples, 1))

    block1 = Conv2D(n_ff[0], (1, 16), use_bias=False, activation='linear', padding='same',
                    name='Spectral_filter_1')(Input_block)
    block1 = BatchNormalization()(block1)
    block1 = DepthwiseConv2D((Chans, 1), use_bias=False, padding='valid', depth_multiplier=n_sf[0], activation='linear',
                             depthwise_constraint=tf.keras.constraints.MaxNorm(max_value=1),
                             name='Spatial_filter_1')(block1)
    block1 = BatchNormalization()(block1)
    block1 = Activation('elu')(block1)

    block2 = Conv2D(n_ff[1], (1, 32), use_bias=False, activation='linear', padding='same',
                    name='Spectral_filter_2')(Input_block)
    block2 = BatchNormalization()(block2)
    block2 = DepthwiseConv2D((Chans, 1), use_bias=False, padding='valid', depth_multiplier=n_sf[1], activation='linear',
                             depthwise_constraint=tf.keras.constraints.MaxNorm(max_value=1),
                             name='Spatial_filter_2')(block2)
    block2 = BatchNormalization()(block2)
    block2 = Activation('elu')(block2)

    block3 = Conv2D(n_ff[2], (1, 64), use_bias=False, activation='linear', padding='same',
                    name='Spectral_filter_3')(Input_block)
    block3 = BatchNormalization()(block3)
    block3 = DepthwiseConv2D((Chans, 1), use_bias=False, padding='valid', depth_multiplier=n_sf[2], activation='linear',
                             depthwise_constraint=tf.keras.constraints.MaxNorm(max_value=1),
                             name='Spatial_filter_3')(block3)
    block3 = BatchNormalization()(block3)
    block3 = Activation('elu')(block3)

    block = Concatenate(axis=-1)([block1, block2, block3])

    block = AveragePooling2D((1, 4))(block)
    block_in = Dropout(drop_rate)(block)

    paddings = tf.constant([[0, 0], [0, 0], [3, 0], [0, 0]])
    block = tf.pad(block_in, paddings, "CONSTANT")
    block = DepthwiseConv2D((1, 4), padding="valid", depth_multiplier=1, dilation_rate=(1, 1))(block)
    block = BatchNormalization()(block)
    block = Activation('elu')(block)
    block = Dropout(drop_rate)(block)
    block = tf.pad(block, paddings, "CONSTANT")
    block = DepthwiseConv2D((1, 4), padding="valid", depth_multiplier=1, dilation_rate=(1, 1))(block)
    block = BatchNormalization()(block)
    block = Activation('elu')(block)
    block = Dropout(drop_rate)(block)
    block_out = Add()([block_in, block])

    paddings = tf.constant([[0, 0], [0, 0], [6, 0], [0, 0]])
    block = tf.pad(block_out, paddings, "CONSTANT")
    block = DepthwiseConv2D((1, 4), padding="valid", depth_multiplier=1, dilation_rate=(1, 2))(block)
    block = BatchNormalization()(block)
    block = Activation('elu')(block)
    block = Dropout(drop_rate)(block)
    block = tf.pad(block, paddings, "CONSTANT")
    block = DepthwiseConv2D((1, 4), padding="valid", depth_multiplier=1, dilation_rate=(1, 2))(block)
    block = BatchNormalization()(block)
    block = Activation('elu')(block)
    block = Dropout(drop_rate)(block)
    block_out = Add()([block_out, block])

    paddings = tf.constant([[0, 0], [0, 0], [12, 0], [0, 0]])
    block = tf.pad(block_out, paddings, "CONSTANT")
    block = DepthwiseConv2D((1, 4), padding="valid", depth_multiplier=1, dilation_rate=(1, 4))(block)
    block = BatchNormalization()(block)
    block = Activation('elu')(block)
    block = Dropout(drop_rate)(block)
    block = tf.pad(block, paddings, "CONSTANT")
    block = DepthwiseConv2D((1, 4), padding="valid", depth_multiplier=1, dilation_rate=(1, 4))(block)
    block = BatchNormalization()(block)
    block = Activation('elu')(block)
    block = Dropout(drop_rate)(block)
    block_out = Add()([block_out, block])

    paddings = tf.constant([[0, 0], [0, 0], [24, 0], [0, 0]])
    block = tf.pad(block_out, paddings, "CONSTANT")
    block = DepthwiseConv2D((1, 4), padding="valid", depth_multiplier=1, dilation_rate=(1, 8))(block)
    block = BatchNormalization()(block)
    block = Activation('elu')(block)
    block = Dropout(drop_rate)(block)
    block = tf.pad(block, paddings, "CONSTANT")
    block = DepthwiseConv2D((1, 4), padding="valid", depth_multiplier=1, dilation_rate=(1, 8))(block)
    block = BatchNormalization()(block)
    block = Activation('elu')(block)
    block = Dropout(drop_rate)(block)
    block_out = Add()([block_out, block])

    block = block_out

    block = Conv2D(28, (1, 1))(block)
    block = BatchNormalization()(block)
    block = Activation('elu')(block)
    #block = AveragePooling2D((4, 1), data_format='Channels_first')(block)

    block = AveragePooling2D(pool_size=(2, 2), data_format='channels_first')(block)



    block = Dropout(drop_rate)(block)
    embedded = Flatten()(block)

    out_class = 4  # Replace with your desired number of output classes
    out = Dense(out_class, activation='softmax', kernel_constraint=max_norm(0.25))(embedded)

    model = Model(inputs=Input_block, outputs=out)
    return model

import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, DepthwiseConv2D, Activation, AveragePooling2D, Dropout, Add, Concatenate, Dense, Flatten
from tensorflow.keras.constraints import max_norm
from tensorflow.keras.models import Model

def create_frozen_EEG_ITNet(Chans, Samples):
    model = EEG_ITNet(Chans, Samples)  #  defined EEG_ITNet function

    # Freeze the last 4 layers
    for layer in model.layers[-4:]:
        layer.trainable = False

    return model

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Activation, Permute, Dropout
from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D
from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import SpatialDropout2D
from tensorflow.keras.regularizers import l1_l2
from tensorflow.keras.layers import Input, Flatten
from tensorflow.keras.constraints import max_norm
from tensorflow.keras import backend as K


def EEGNet_FirstLayerOnly(nb_classes, Chans=64, Samples=128,
           dropoutRate=0.5, kernLength=64, F1=8,
           D=2, F2=16, norm_rate=0.25, dropoutType='Dropout'):
    """ Keras Implementation of EEGNet
    ...
    (Rest of the function remains the same)
    ...
    """

    if dropoutType == 'SpatialDropout2D':
        dropoutType = SpatialDropout2D
    elif dropoutType == 'Dropout':
        dropoutType = Dropout
    else:
        raise ValueError('dropoutType must be one of SpatialDropout2D '
                         'or Dropout, passed as a string.')

    input1 = Input(shape=(Chans, Samples, 1))

    ##################################################################
    block1 = Conv2D(F1, (1, kernLength), padding='same',
                    input_shape=(Chans, Samples, 1),
                    use_bias=False)(input1)
    block1 = BatchNormalization()(block1)
    block1 = DepthwiseConv2D((Chans, 1), use_bias=False,
                             depth_multiplier=D,
                             depthwise_constraint=max_norm(1.))(block1)
    block1 = BatchNormalization()(block1)
    block1 = Activation('elu')(block1)
    block1 = AveragePooling2D((1, 4))(block1)
    block1 = dropoutType(dropoutRate)(block1)

    block2 = SeparableConv2D(F2, (1, 16),
                             use_bias=False, padding='same')(block1)
    block2 = BatchNormalization()(block2)
    block2 = Activation('elu')(block2)
    block2 = AveragePooling2D((1, 8))(block2)
    block2 = dropoutType(dropoutRate)(block2)

    flatten = Flatten(name='flatten')(block2)

    dense = Dense(nb_classes, name='dense',
                  kernel_constraint=max_norm(norm_rate))(flatten)
    softmax = Activation('softmax', name='softmax')(dense)

    # Create the model
    model = Model(inputs=input1, outputs=softmax)

    # Freeze all layers except the first layer
    for layer in model.layers[1:]:
        layer.trainable = False

    return model

import matplotlib.pyplot as plt

def plot_training_history(history):
    # Plot training & validation accuracy values
    plt.figure(figsize=(10, 5))
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('Model Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend(['Train', 'Validation'], loc='upper left')

    plt.tight_layout()
    plt.show()

import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, DepthwiseConv2D, Activation, AveragePooling2D, Dropout, Add, Concatenate, Dense, Flatten
from tensorflow.keras.constraints import max_norm
from tensorflow.keras.models import Model

def EEG_ITNet_FirstTwoLayers(Chans, Samples):
    Input_block = Input(shape=(Chans, Samples, 1))
    #using only the first two layers of the original EEG-ITNet

    block1 = Conv2D(2, (1, 16), use_bias=False, activation='linear', padding='same', name='Spectral_filter_1')(Input_block)
    block1 = BatchNormalization()(block1)
    block1 = DepthwiseConv2D((Chans, 1), use_bias=False, padding='valid', depth_multiplier=1, activation='linear', depthwise_constraint=tf.keras.constraints.MaxNorm(max_value=1), name='Spatial_filter_1')(block1)
    block1 = BatchNormalization()(block1)
    block1 = Activation('elu')(block1)

    block2 = Conv2D(4, (1, 32), use_bias=False, activation='linear', padding='same', name='Spectral_filter_2')(Input_block)
    block2 = BatchNormalization()(block2)
    block2 = DepthwiseConv2D((Chans, 1), use_bias=False, padding='valid', depth_multiplier=1, activation='linear', depthwise_constraint=tf.keras.constraints.MaxNorm(max_value=1), name='Spatial_filter_2')(block2)
    block2 = BatchNormalization()(block2)
    block2 = Activation('elu')(block2)

    block = Concatenate(axis=-1)([block1, block2])
    block = AveragePooling2D((1, 4))(block)
    block_in = Dropout(0.4)(block)

    model = Model(inputs=Input_block, outputs=block_in)

    # Freeze the layers
    for layer in model.layers:
        layer.trainable = False

    return model

import mne
import numpy as np

def create_raw_eeg_object(data):
    # Define the channel names
    ch_names = ['FP1', 'FPZ', 'FP2', 'AF3', 'AF4', 'F7', 'F5', 'F3', 'F1', 'FZ', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1', 'FCZ', 'FC2', 'FC4', 'FC6', 'FT8', 'T7', 'C5', 'C3', 'C1', 'CZ', 'C2', 'C4', 'C6', 'T8', 'TP7', 'CP5', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'CP6', 'TP8', 'P7', 'P5', 'P3', 'P1', 'PZ', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO5', 'PO3', 'POZ', 'PO4', 'PO6', 'PO8', 'CB1', 'O1', 'OZ', 'O2', 'CB2']

    # Define the sampling frequency
    sfreq = 100

    # Create the MNE-Python Info object
    ch_types = ['eeg'] * len(ch_names)
    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)

    # Create a Raw object from the data and info
    raw = mne.io.RawArray(data / 1e6, info)

    # Plot the raw EEG data for visualization
    # raw.plot(show_scrollbars=True, show_scalebars=True, n_channels=raw.info['nchan'])

    return raw

import matplotlib.pyplot as plt
import numpy as np

def plot_eeg_channels(eeg_data):
    num_channels = eeg_data.shape[0]  # Number of channels
    num_samples = eeg_data.shape[1]  # Number of samples
    plt.figure(figsize=(15, 3))
    plt.plot(eeg_data.T)
    plt.show()

import tensorflow as tf
def get_categorical_labels_Cross(label_list_S1, label_list_S2, label_list_S3):
    categorical_labels_S1 = tf.keras.utils.to_categorical(label_list_S1)
    #print("categorical_labels_S1:", categorical_labels_S1.shape)

    categorical_labels_S2 = tf.keras.utils.to_categorical(label_list_S2)
    #print("categorical_labels_S1:", categorical_labels_S1.shape)

    categorical_labels_S3 = tf.keras.utils.to_categorical(label_list_S3)
    #print("categorical_labels_S1:", categorical_labels_S1.shape)

    return categorical_labels_S1, categorical_labels_S2, categorical_labels_S3